{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFB0f6skK6KP"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U segmentation-models"
      ],
      "metadata": {
        "id": "1M0C9BYyK7vP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras==2.3.1"
      ],
      "metadata": {
        "id": "kRi0D5EjK84H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow --upgrade"
      ],
      "metadata": {
        "id": "-_TIz4zPK-04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "id": "ulV086EfLAMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
        "\n",
        "from tensorflow import keras\n",
        "import segmentation_models as sm"
      ],
      "metadata": {
        "id": "Xz9kD8HMLBS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U albumentations>=0.3.0 --user\n",
        "!pip install -U --pre segmentation-models --user"
      ],
      "metadata": {
        "id": "UkToJajkLClH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import segmentation_models as sm\n",
        "import albumentations as A\n",
        "\n",
        "# Data directory on Google Drive\n",
        "DATA_DIR = '/content/drive/My Drive/'\n",
        "\n",
        "# Update paths for training, validation, and test sets\n",
        "x_train_dir = os.path.join(DATA_DIR, 'train/images')\n",
        "y_train_dir = os.path.join(DATA_DIR, 'train/masks')\n",
        "\n",
        "x_valid_dir = os.path.join(DATA_DIR, 'val/images')\n",
        "y_valid_dir = os.path.join(DATA_DIR, 'val/masks')\n",
        "\n",
        "x_test_dir = os.path.join(DATA_DIR, 'test/images')\n",
        "y_test_dir = os.path.join(DATA_DIR, 'test/masks')\n",
        "\n",
        "\n",
        "# Our helper function used for visualizing images\n",
        "def visualize(**images):\n",
        "    \"\"\"Plot images in one row.\"\"\"\n",
        "    n = len(images)\n",
        "    plt.figure(figsize=(16, 5)) #A plot figure is created using the Matplotlib library. The figsize parameter determines the drawing size.\n",
        "    for i, (name, image) in enumerate(images.items()):#Each image is shown in a separate subplot.\n",
        "        plt.subplot(1, n, i + 1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.title(' '.join(name.split('_')).title())\n",
        "        plt.imshow(image)\n",
        "    plt.show()\n",
        "\n",
        "# Dataset class\n",
        "# It is used to process the dataset and provide the necessary data samples for training or evaluation of the model.\n",
        "class Dataset:\n",
        "    def __init__(self, images_dir, masks_dir, classes=None, augmentation=None, preprocessing=None):\n",
        "        self.ids = os.listdir(images_dir)  #ids: List containing the names of image and mask files.\n",
        "        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids] #images_fps: List containing the full path of image files.\n",
        "        self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids] #masks_fps: List containing the full path to mask files.\n",
        "        self.class_values = {cls.lower(): idx for idx, cls in enumerate(classes)} #A dictionary where classes are named with lowercase letters and paired with indices.\n",
        "        self.augmentation = augmentation\n",
        "        self.preprocessing = preprocessing\n",
        "\n",
        "    def __getitem__(self, i): #This method returns a specific element from the dataset. The i parameter represents the index of the item to retrieve.\n",
        "        image = cv2.imread(self.images_fps[i])\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = cv2.resize(image, (512, 512))\n",
        "\n",
        "        mask = np.zeros((image.shape[0], image.shape[1], len(self.class_values)), dtype=np.uint8)\n",
        "\n",
        "        for cls, idx in self.class_values.items():\n",
        "            if cls.lower() == 'minor':\n",
        "                cls = 'no damage'\n",
        "            elif cls.lower() == 'major':\n",
        "                cls = 'damaged'\n",
        "\n",
        "            cls_mask = cv2.imread(self.masks_fps[i], cv2.IMREAD_COLOR)\n",
        "            cls_mask = cv2.resize(cls_mask, (512, 512))\n",
        "            mask[..., idx] = (cls_mask == np.array(eval(cls))[None, None, :]).all(axis=-1).astype('uint8')\n",
        "\n",
        "        if self.augmentation:\n",
        "            sample = self.augmentation(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "\n",
        "        if self.preprocessing:\n",
        "            sample = self.preprocessing(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "\n",
        "        return image, mask.astype('float32')\n",
        "\n",
        "    def __len__(self): #This method returns the total number of elements of the dataset. This method runs when len(dataset) is called.\n",
        "        return len(self.ids)\n",
        "\n",
        "# Dataloader\n",
        "# Dataloader class is used to retrieve mini-batches from the dataset and organize these mini-groups during training or evaluation of the model.\n",
        "\n",
        "class Dataloader(keras.utils.Sequence):\n",
        "    def __init__(self, dataset, batch_size=1, shuffle=False):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.indexes = np.arange(len(dataset))\n",
        "\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        start = i * self.batch_size\n",
        "        stop = (i + 1) * self.batch_size\n",
        "        data = [self.dataset[j] for j in range(start, stop)]\n",
        "\n",
        "        images = [item[0] for item in data]\n",
        "        masks = [item[1] for item in data]\n",
        "\n",
        "        batch = [np.stack(images, axis=0), np.stack(masks, axis=0)]\n",
        "        return batch\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indexes) // self.batch_size\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            self.indexes = np.random.permutation(self.indexes)\n",
        "\n",
        "# Input dimensions\n",
        "INPUT_HEIGHT = 512\n",
        "INPUT_WIDTH = 512\n",
        "CHANNELS = 3 #It is stated that since the images are in color, each pixel contains 3 color channels (RGB).\n",
        "\n",
        "# Specify data preprocessing functions\n",
        "def get_preprocessing(preprocessing_fn=None):\n",
        "    if preprocessing_fn:\n",
        "        _transform = [\n",
        "            A.Lambda(image=preprocessing_fn),\n",
        "        ]\n",
        "    else:\n",
        "        _transform = []\n",
        "\n",
        "    return A.Compose(_transform)\n",
        "\n",
        "# Specify augmentation functions for training\n",
        "def get_training_augmentation():\n",
        "    train_transform = [\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, p=1, border_mode=0),\n",
        "        A.PadIfNeeded(min_height=INPUT_HEIGHT, min_width=INPUT_WIDTH, always_apply=True, border_mode=0),\n",
        "        A.RandomCrop(height=INPUT_HEIGHT, width=INPUT_WIDTH, always_apply=True),\n",
        "        A.IAAAdditiveGaussianNoise(p=0.2),\n",
        "        A.IAAPerspective(p=0.5),\n",
        "        A.OneOf(\n",
        "            [\n",
        "                A.CLAHE(p=1),\n",
        "                A.RandomBrightness(p=1),\n",
        "                A.RandomGamma(p=1),\n",
        "            ],\n",
        "            p=0.9,\n",
        "        ),\n",
        "        A.OneOf(\n",
        "            [\n",
        "                A.IAASharpen(p=1),\n",
        "                A.Blur(blur_limit=3, p=1),\n",
        "                A.MotionBlur(blur_limit=3, p=1),\n",
        "            ],\n",
        "            p=0.9,\n",
        "        ),\n",
        "        A.OneOf(\n",
        "            [\n",
        "                A.RandomContrast(p=1),\n",
        "                A.HueSaturationValue(p=1),\n",
        "            ],\n",
        "            p=0.9,\n",
        "        ),\n",
        "    ]\n",
        "    return A.Compose(train_transform)\n",
        "\n",
        "# Create an instance of the training dataset\n",
        "damage_classes = ['(0, 255, 0)', '(0, 255, 255)', '(255, 0, 0)', '(0, 0, 255)']\n",
        "train_dataset = Dataset(x_train_dir, y_train_dir, classes=damage_classes, augmentation=get_training_augmentation(),\n",
        "                        preprocessing=get_preprocessing())train_dataset\n",
        "\n",
        "# Create an instance of the validation dataset\n",
        "valid_dataset = Dataset(x_valid_dir, y_valid_dir, classes=damage_classes, augmentation=get_training_augmentation(),\n",
        "                        preprocessing=get_preprocessing())\n",
        "\n",
        "# Define UNet model\n",
        "BACKBONE = 'efficientnetb3'\n",
        "CLASSES = ['No Damage', 'Minor', 'Major', 'Damaged']\n",
        "LR = 0.0001\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 4\n",
        "\n",
        "# Create the UNet model\n",
        "model = sm.Unet(BACKBONE, classes=len(CLASSES), activation='softmax', input_shape=(INPUT_HEIGHT, INPUT_WIDTH, CHANNELS))\n",
        "\n",
        "# Define optimizer and loss functions\n",
        "optim = keras.optimizers.Adam(LR)\n",
        "\n",
        "# Loss functions\n",
        "dice_loss = sm.losses.DiceLoss()\n",
        "focal_loss = sm.losses.CategoricalFocalLoss()\n",
        "total_loss = dice_loss + (1 * focal_loss)\n",
        "\n",
        "# Metrics\n",
        "metrics = [sm.metrics.IOUScore(name='iou_score', threshold=0.5), sm.metrics.FScore(name='f1-score', threshold=0.5)]\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optim, total_loss, metrics)\n",
        "\n",
        "# Create an instance of the training dataset without augmentation for DataLoader NO AUGMENTATION\n",
        "#train_dataset = Dataset(x_train_dir, y_train_dir, classes=damage_classes, augmentation=None,\n",
        "#                        preprocessing=get_preprocessing())\n",
        "\n",
        "# Create an instance of the validation dataset without augmentation for DataLoader NO AUGMENTATION\n",
        "#valid_dataset = Dataset(x_valid_dir, y_valid_dir, classes=damage_classes, augmentation=None,\n",
        "#                        preprocessing=get_preprocessing())\n",
        "\n",
        "# Dataloaders without augmentation\n",
        "train_dataloader = Dataloader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "valid_dataloader = Dataloader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Model Checkpoint, save the best weights to Google Drive\n",
        "model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "    '/content/drive/My Drive/best_model.h5',\n",
        "    save_weights_only=True,\n",
        "    save_best_only=True,\n",
        "    monitor='val_iou_score',\n",
        "    mode='max',\n",
        ")\n",
        "\n",
        "# Learning Rate Reduction\n",
        "lr_reduce = keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.1,\n",
        "    patience=5,\n",
        "    min_lr=0.00001,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_dataloader,\n",
        "    steps_per_epoch=len(train_dataloader),\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[model_checkpoint, lr_reduce],\n",
        "    validation_data=valid_dataloader,\n",
        "    validation_steps=len(valid_dataloader),\n",
        ")\n",
        "\n",
        "# Create an instance of the test dataset\n",
        "test_dataset = Dataset(\n",
        "    x_test_dir,\n",
        "    y_test_dir,\n",
        "    classes=damage_classes,\n",
        "    augmentation=get_training_augmentation(),  # Use training augmentation for testing as well\n",
        "    preprocessing=get_preprocessing()\n",
        ")\n",
        "\n",
        "# Create test dataloader\n",
        "test_dataloader = Dataloader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# Load the best weights\n",
        "model.load_weights('/content/drive/My Drive/best_model.h5')\n",
        "\n",
        "# Evaluate the model\n",
        "scores = model.evaluate(test_dataloader)\n",
        "\n"
      ],
      "metadata": {
        "id": "z58FSNdGLH5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation iou_score values\n",
        "plt.figure(figsize=(30, 5))\n",
        "plt.subplot(121)\n",
        "if 'iou_score' in history.history:\n",
        "    plt.plot(history.history['iou_score'])\n",
        "if 'val_iou_score' in history.history:\n",
        "    plt.plot(history.history['val_iou_score'])\n",
        "plt.title('Model IOU Score')\n",
        "plt.ylabel('IOU Score')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(122)\n",
        "if 'loss' in history.history:\n",
        "    plt.plot(history.history['loss'])\n",
        "if 'val_loss' in history.history:\n",
        "    plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Ow1rMZzOLdLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the test dataset\n",
        "test_dataset = Dataset(\n",
        "    x_test_dir,\n",
        "    y_test_dir,\n",
        "    classes=damage_classes,\n",
        "    augmentation=None,  # Use training augmentation for testing as well\n",
        "    preprocessing=get_preprocessing()\n",
        ")\n",
        "# Number of random samples to visualize\n",
        "n = 20\n",
        "# Randomly select 'n' indices from the test dataset\n",
        "ids = np.random.choice(np.arange(len(test_dataset)), size=n)\n",
        "\n",
        "for i in ids:\n",
        "    image, gt_mask = test_dataset[i]\n",
        "    # Resize the image to the expected size of the model from the test dataset\n",
        "    image = cv2.resize(image, (512, 512))\n",
        "    # Add an extra dimension to match the model's input shape\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    # Predict the mask using the trained model\n",
        "    pr_mask = model.predict(image)\n",
        "\n",
        "    # Resize the ground truth mask\n",
        "    gt_mask_resized = cv2.resize(gt_mask, (512, 512))\n",
        "\n",
        "    # Specify class titles\n",
        "    titles = ['No Damage', 'Minor', 'Major', 'Damaged']\n",
        "\n",
        "    # Visualize for each class, skipping 'Minor' and 'Major'\n",
        "    for class_idx in range(pr_mask.shape[-1]):\n",
        "        if titles[class_idx] in ['Minor', 'Major']:\n",
        "            continue  # Skip visualization for 'Minor' and 'Major' classes\n",
        "\n",
        "        # Show the original image\n",
        "        plt.figure(figsize=(16, 5))\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(image.squeeze())\n",
        "        plt.title('Original Image')\n",
        "\n",
        "        # Show the ground truth mask\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(gt_mask_resized[..., class_idx].squeeze(), cmap='gray')\n",
        "        plt.title(f'Ground Truth {titles[class_idx]} Mask')\n",
        "\n",
        "        # Show the predicted mask\n",
        "        pr_mask_bw = (pr_mask[..., class_idx] > 0.5).astype(np.uint8)\n",
        "        pr_mask_resized = cv2.resize(pr_mask_bw.squeeze(), (512, 512))\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(pr_mask_resized, cmap='gray')\n",
        "        plt.title(f'Predicted {titles[class_idx]} Mask (BW)')\n",
        "\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "aQ4YtNgjLe14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the directory to save the model\n",
        "model_save_path = '/content/drive/MyDrive/model_v15/model2.h5'\n",
        "\n",
        "# Save the model\n",
        "model.save(model_save_path)"
      ],
      "metadata": {
        "id": "BGF8-5bBLhhO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}